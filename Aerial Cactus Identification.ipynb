{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport keras\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, Dense, Flatten, BatchNormalization, Dropout, LeakyReLU, DepthwiseConv2D, Flatten\nfrom keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\nfrom keras.layers import Conv2D, MaxPool2D, MaxPooling2D\nfrom keras.layers.pooling import GlobalAveragePooling2D\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n\n\nfrom sklearn.metrics import confusion_matrix, roc_auc_score, classification_report\nfrom sklearn.model_selection import train_test_split\n\nfrom tqdm import tqdm, tqdm_notebook\n\nimport cv2 as cv\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport gc\n\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv')\nsub_df = pd.read_csv('../input/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()\ntrain_df.has_cactus.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_path = '../input/train/train/'\ntest_path = '../input/test/test/'\n\nimages_train = []\nlabels_train = []\n\nimages = train_df['id'].values\nfor image_id in tqdm_notebook(images):\n    \n    image = np.array(cv.imread(training_path + image_id))\n    label = train_df[train_df['id'] == image_id]['has_cactus'].values[0]\n    \n    images_train.append(image)\n    labels_train.append(label)\n    \n    \n    # custom image augmentation by fliping the image upside down\n    images_train.append(np.flip(image))\n    labels_train.append(label)\n    \n    # custom image augmentation by fliping the image upside down\n    images_train.append(np.flipud(image))\n    labels_train.append(label)\n    \n    # custom image augmentation by fliping the image diagonally\n    images_train.append(np.fliplr(image))\n    labels_train.append(label)\n    \n    \nimages_train = np.asarray(images_train)\nimages_train = images_train.astype('float32')\nimages_train /= 255.\n\nlabels_train = np.asarray(labels_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model():\n    \n    from numpy.random import seed\n    seed(42)\n    from tensorflow import set_random_seed\n    set_random_seed(42)\n    \n    model = Sequential()\n        \n    model.add(Conv2D(3, kernel_size = 3, activation = 'relu', input_shape = (32, 32, 3)))\n    \n    model.add(Conv2D(filters = 16, kernel_size = 3, activation = 'relu'))\n    model.add(Conv2D(filters = 16, kernel_size = 3, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    \n    model.add(Conv2D(filters = 32, kernel_size = 3, activation = 'relu'))\n    model.add(Conv2D(filters = 64, kernel_size = 3, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    \n    model.add(Conv2D(filters = 64, kernel_size = 3, activation = 'relu'))\n    model.add(Conv2D(filters = 128, kernel_size = 3, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    \n    model.add(Conv2D(filters = 128, kernel_size = 3, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters = 256, kernel_size = 3, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    \n    model.add(Conv2D(filters = 256, kernel_size = 3, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters = 512, kernel_size = 3, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    \n    model.add(GlobalAveragePooling2D())\n    \n    model.add(Dense(470, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(256, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(128, activation = 'tanh'))\n    \n    model.add(Dense(1, activation = 'sigmoid'))\n\n    model.compile(Adam(lr = 0.001), loss = 'binary_crossentropy', metrics = ['accuracy'])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_images_names = []\n\nfor filename in os.listdir(test_path):\n    test_images_names.append(filename)\n    \ntest_images_names.sort()\n\nimages_test = []\n\nfor image_id in tqdm_notebook(test_images_names):\n    images_test.append(np.array(cv.imread(test_path + image_id)))\n    \nimages_test = np.asarray(images_test)\nimages_test = images_test.astype('float32')\nimages_test /= 255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_valid, y_train, y_valid = train_test_split(images_train, labels_train, test_size = 0.2, stratify = labels_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = create_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_training_curves(history):\n    acc = history.history['acc']\n    val_acc = history.history['val_acc']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    \n    epochs = range(1, len(acc) + 1)\n    \n    plt.plot(epochs, loss, 'r', label='Training loss')\n    plt.plot(epochs, val_loss, 'g', label='Validation loss')\n    plt.title('Losses')\n    plt.legend()\n    plt.figure()\n    \n    plt.plot(epochs, acc, 'r', label='Training acc')\n    plt.plot(epochs, val_acc, 'g', label='Validation acc')\n    plt.title('Accuracies')\n    plt.legend()\n    plt.figure()\n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64 \nepochs = 50\n\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.callbacks import EarlyStopping\n\nmodel.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.Adam(0.01), \n              metrics=['accuracy'])\n\ncheckpointer = ModelCheckpoint(monitor='val_acc', mode='max', filepath='model.hdf5', verbose=2, save_best_only=True)\nearlyStopping = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=0, mode='max')\n\nhistory = model.fit(x = x_train, y = y_train, validation_data=(x_valid, y_valid), epochs=epochs, batch_size=batch_size, verbose=2, callbacks=[checkpointer, earlyStopping])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights(\"model.hdf5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(images_test, verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_training_curves(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_probability = model.predict_proba(images_train)\n\ny_pred = model.predict_classes(images_train)\nconf_matrix = confusion_matrix(labels_train, y_pred)\nfig, ax = plt.subplots(figsize = (10, 10))\n\nsns.heatmap(conf_matrix, annot = True, fmt = 'd', xticklabels = ['0', '1'], yticklabels = ['0', '1'])\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.show()\n\nprint(classification_report(labels_train, y_pred, target_names = ['0','1']))\nprint(\"\\n\\n AUC: {:<0.4f}\".format(roc_auc_score(labels_train, y_pred_probability)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.read_csv('../input/sample_submission.csv')\nX_test = []\nimages_test = sub_df['id'].values\n\nfor img_id in tqdm_notebook(images_test):\n    X_test.append(cv.imread(test_path + img_id))\n    \nX_test = np.asarray(X_test)\nX_test = X_test.astype('float32')\nX_test /= 255\n\ny_test_pred = model.predict_proba(X_test)\n\nsub_df['has_cactus'] = y_test_pred\nsub_df.to_csv('aerial-cactus-submission.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}